{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, KFold\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>months_as_customer</th>\n",
       "      <th>age</th>\n",
       "      <th>policy_number</th>\n",
       "      <th>policy_state</th>\n",
       "      <th>policy_csl</th>\n",
       "      <th>policy_deductable</th>\n",
       "      <th>policy_annual_premium</th>\n",
       "      <th>umbrella_limit</th>\n",
       "      <th>insured_zip</th>\n",
       "      <th>insured_sex</th>\n",
       "      <th>...</th>\n",
       "      <th>policy_bind_date_year</th>\n",
       "      <th>policy_bind_date_cosine_month</th>\n",
       "      <th>policy_bind_date_sine_month</th>\n",
       "      <th>policy_bind_date_cosine_day</th>\n",
       "      <th>policy_bind_date_sine_day</th>\n",
       "      <th>incident_date_year</th>\n",
       "      <th>incident_date_cosine_month</th>\n",
       "      <th>incident_date_sine_month</th>\n",
       "      <th>incident_date_cosine_day</th>\n",
       "      <th>incident_date_sine_day</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>328</td>\n",
       "      <td>48</td>\n",
       "      <td>521585</td>\n",
       "      <td>OH</td>\n",
       "      <td>250/500</td>\n",
       "      <td>1000</td>\n",
       "      <td>1406.91</td>\n",
       "      <td>0</td>\n",
       "      <td>466132</td>\n",
       "      <td>MALE</td>\n",
       "      <td>...</td>\n",
       "      <td>2014</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>228</td>\n",
       "      <td>42</td>\n",
       "      <td>342868</td>\n",
       "      <td>IN</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1197.22</td>\n",
       "      <td>5000000</td>\n",
       "      <td>468176</td>\n",
       "      <td>MALE</td>\n",
       "      <td>...</td>\n",
       "      <td>2006</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>5.510911e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>-4.286264e-16</td>\n",
       "      <td>-1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>134</td>\n",
       "      <td>29</td>\n",
       "      <td>687698</td>\n",
       "      <td>OH</td>\n",
       "      <td>100/300</td>\n",
       "      <td>2000</td>\n",
       "      <td>1413.14</td>\n",
       "      <td>5000000</td>\n",
       "      <td>430632</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>...</td>\n",
       "      <td>2000</td>\n",
       "      <td>-1.836970e-16</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>256</td>\n",
       "      <td>41</td>\n",
       "      <td>227811</td>\n",
       "      <td>IL</td>\n",
       "      <td>250/500</td>\n",
       "      <td>2000</td>\n",
       "      <td>1415.74</td>\n",
       "      <td>6000000</td>\n",
       "      <td>608117</td>\n",
       "      <td>FEMALE</td>\n",
       "      <td>...</td>\n",
       "      <td>1990</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>8.660254e-01</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>5.000000e-01</td>\n",
       "      <td>-0.866025</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>228</td>\n",
       "      <td>44</td>\n",
       "      <td>367455</td>\n",
       "      <td>IL</td>\n",
       "      <td>500/1000</td>\n",
       "      <td>1000</td>\n",
       "      <td>1583.91</td>\n",
       "      <td>6000000</td>\n",
       "      <td>610706</td>\n",
       "      <td>MALE</td>\n",
       "      <td>...</td>\n",
       "      <td>2014</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>-1.000000e+00</td>\n",
       "      <td>1.224647e-16</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>-8.660254e-01</td>\n",
       "      <td>0.500000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 45 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   months_as_customer  age  policy_number policy_state policy_csl  \\\n",
       "0                 328   48         521585           OH    250/500   \n",
       "1                 228   42         342868           IN    250/500   \n",
       "2                 134   29         687698           OH    100/300   \n",
       "3                 256   41         227811           IL    250/500   \n",
       "4                 228   44         367455           IL   500/1000   \n",
       "\n",
       "   policy_deductable  policy_annual_premium  umbrella_limit  insured_zip  \\\n",
       "0               1000                1406.91               0       466132   \n",
       "1               2000                1197.22         5000000       468176   \n",
       "2               2000                1413.14         5000000       430632   \n",
       "3               2000                1415.74         6000000       608117   \n",
       "4               1000                1583.91         6000000       610706   \n",
       "\n",
       "  insured_sex  ... policy_bind_date_year policy_bind_date_cosine_month  \\\n",
       "0        MALE  ...                  2014                  5.000000e-01   \n",
       "1        MALE  ...                  2006                 -1.000000e+00   \n",
       "2      FEMALE  ...                  2000                 -1.836970e-16   \n",
       "3      FEMALE  ...                  1990                 -8.660254e-01   \n",
       "4        MALE  ...                  2014                 -1.000000e+00   \n",
       "\n",
       "  policy_bind_date_sine_month policy_bind_date_cosine_day  \\\n",
       "0               -8.660254e-01               -8.660254e-01   \n",
       "1                1.224647e-16                5.510911e-16   \n",
       "2               -1.000000e+00               -1.000000e+00   \n",
       "3                5.000000e-01                8.660254e-01   \n",
       "4                1.224647e-16               -1.000000e+00   \n",
       "\n",
       "   policy_bind_date_sine_day  incident_date_year incident_date_cosine_month  \\\n",
       "0               5.000000e-01                2015                   0.866025   \n",
       "1               1.000000e+00                2015                   0.866025   \n",
       "2               1.224647e-16                2015                   0.500000   \n",
       "3               5.000000e-01                2015                   0.866025   \n",
       "4               1.224647e-16                2015                   0.500000   \n",
       "\n",
       "  incident_date_sine_month incident_date_cosine_day incident_date_sine_day  \n",
       "0                 0.500000             8.660254e-01               0.500000  \n",
       "1                 0.500000            -4.286264e-16              -1.000000  \n",
       "2                 0.866025             5.000000e-01              -0.866025  \n",
       "3                 0.500000             5.000000e-01              -0.866025  \n",
       "4                 0.866025            -8.660254e-01               0.500000  \n",
       "\n",
       "[5 rows x 45 columns]"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('featuure_engineered.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Duplicated rows: 0\n",
      "Missing values: 91\n"
     ]
    }
   ],
   "source": [
    "print('Duplicated rows:', df.duplicated().sum())\n",
    "print('Missing values:', df.isna().sum().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from sklearn.pipeline import Pipeline\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Select categorical columns for one-hot encoding and numeric columns for scaling\n",
    "numeric_features = df.select_dtypes(exclude='object').columns.tolist()\n",
    "categorical_features = df.select_dtypes(include='object').columns.tolist()\n",
    "\n",
    "# Remove target feature from categorica list\n",
    "categorical_features.remove('fraud_reported')\n",
    "# Preprocessing the features\n",
    "preprocessor = ColumnTransformer(\n",
    "    transformers=[\n",
    "        ('cat_encoder', OneHotEncoder(drop='first', sparse_output=False),\n",
    "         categorical_features),\n",
    "        ('scaler', StandardScaler(), numeric_features)\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining X and y\n",
    "X = df.drop(columns=['fraud_reported']) \n",
    "y = df['fraud_reported']\n",
    "\n",
    "#performing LabelEncoding\n",
    "from sklearn.preprocessing import LabelBinarizer\n",
    "lb = LabelBinarizer()\n",
    "y = lb.fit_transform(y)\n",
    "\n",
    "\n",
    "# Split into training and test sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.25, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_preprocessed = preprocessor.fit_transform(X_train)\n",
    "X_test_preprocessed = preprocessor.transform(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['N', 'Y'], dtype='<U1')"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lb.classes_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`0 represents N: not fraud case`\n",
    "\n",
    "`1 represents Y: fraud case`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "fraud_reported\n",
       "N    0.753\n",
       "Y    0.247\n",
       "Name: proportion, dtype: float64"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['fraud_reported'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Noted some class imbalance in the target column. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.base import clone\n",
    "from sklearn.metrics import recall_score, precision_score, f1_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Modeling:\n",
    "    \"\"\"Class to carry out model fiting and cross validation\n",
    "    Attributes:\n",
    "        model: The model \n",
    "        X_train: training features\n",
    "        y_train: target\n",
    "    \"\"\"\n",
    "    def __init__(self, model, preprocessor, X_train, y_train):\n",
    "        self.model = model\n",
    "        self.X_train = X_train\n",
    "        self.y_train = y_train\n",
    "        self.preprocessor = preprocessor\n",
    "\n",
    "    def train_base(self):\n",
    "        \"\"\"Fif with only preprocessing which only includes scaling and ohe\"\"\"\n",
    "        # Fit the model\n",
    "        model_pipe = Pipeline([\n",
    "            ('preprocessing', self.preprocessor),\n",
    "            ('model', self.model)\n",
    "        ])\n",
    "        score = cross_val_score(model_pipe,\n",
    "                                self.X_train,\n",
    "                                self.y_train,\n",
    "                                scoring='accuracy',\n",
    "                                ).mean() \n",
    "        \n",
    "        print(\"\\n\"f\"The model(with normal preprocessing) has an accuracy of {score*100:.2f}%\")\n",
    "        self.model = model_pipe\n",
    "        self.model.fit(self.X_train, self.y_train)\n",
    "        return self.model\n",
    "        \n",
    "    def train_with_smote(self):\n",
    "        \"\"\"Includes oversampling with smote to reduce class imbalance\"\"\"\n",
    "        # Perform Cross-Validation\n",
    "        scores = []\n",
    "        # splits for cross validation\n",
    "        skf = StratifiedKFold(n_splits=3, random_state=42)\n",
    "        for i, (train_idx, test_idx) in enumerate(skf.split(self.X_train, self.y_train)):\n",
    "            # train and test data for the validation\n",
    "            cv_X_train = self.X_train.iloc[train_idx, :]\n",
    "            cv_X_test = self.X_train.iloc[test_idx, :]\n",
    "            cv_y_train = self.y_train[train_idx]\n",
    "            cv_y_test = self.y_train[test_idx]\n",
    "            \n",
    "            preprocessor_clone = clone(preprocessor)\n",
    "            \n",
    "            # preprocessing the features\n",
    "            cv_X_train_preprocessed = preprocessor_clone.fit_transform(cv_X_train)\n",
    "            cv_X_test_preprocessed = preprocessor_clone.transform(cv_X_test)\n",
    "            \n",
    "            # Retrieve column names from each transformer\n",
    "            if i == 0:\n",
    "                column_names = []\n",
    "                for name, transformer, columns in preprocessor_clone.transformers_:\n",
    "                    if hasattr(transformer, 'get_feature_names_out'):\n",
    "                        column_names.extend(transformer.get_feature_names_out(columns))\n",
    "                    else:\n",
    "                        column_names.extend(columns) \n",
    "            \n",
    "            # cloning the model\n",
    "            model_clone = clone(self.model)\n",
    "            print(column_names)\n",
    "            return\n",
    "            \n",
    "            # oversampling with smote to fix class imbalance\n",
    "            X_oversampled, y_oversampled = SMOTE().fit_resample(cv_X_train_preprocessed, cv_y_train)\n",
    "            X_oversampled = pd.DataFrame(X_oversampled, columns=column_names)\n",
    "            model_clone.fit(X_oversampled, y_oversampled)\n",
    "            score = model_clone.score(cv_X_test_preprocessed, cv_y_test)\n",
    "            scores.append(score)\n",
    "        \n",
    "        cv_X_train_preprocessed = preprocessor.fit_transform(self.X_train)\n",
    "        \n",
    "        X_oversampled, y_oversampled = SMOTE().fit_resample(cv_X_train_preprocessed, self.y_train)\n",
    "        \n",
    "        print(\"\\n\"f\"The model(with SMOTE) has an accuracy of {np.mean(scores)*100:.2f}%\")\n",
    "        self.model.fit(X_oversampled, y_oversampled)\n",
    "        return self.model\n",
    "    \n",
    "    def evaluate_on_test(self, X_test, y_test):\n",
    "        \"\"\"evaluates the model on unseen test data\"\"\"\n",
    "        y_pred = self.model.predict(X_test)\n",
    "        print('Recall Score:', recall_score(y_test, y_pred))\n",
    "        print('Precision Score:', precision_score(y_test, y_pred))\n",
    "        print('F1 Score:', f1_score(y_test, y_pred))\n",
    "            \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The model(with normal preprocessing) has an accuracy of 81.73%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "log_reg = LogisticRegression(solver='liblinear')\n",
    "\n",
    "model_1 = Modeling(log_reg, preprocessor, X_train, y_train)\n",
    "\n",
    "fitted_model_1 = model_1.train_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitted_model_1_smote = model_1.train_with_smote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_clf = RandomForestClassifier()\n",
    "model_2 = Modeling(rf_clf, preprocessor, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The model(with normal preprocessing) has an accuracy of 76.80%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\pipeline.py:405: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  self._final_estimator.fit(Xt, y, **fit_params_last_step)\n"
     ]
    }
   ],
   "source": [
    "fitted_model_2 = model_2.train_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitted_model_2_smote = model_2.train_with_smote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb = XGBClassifier(\n",
    "    colsample_bytree=1.0,\n",
    "    gamma=0,\n",
    "    learning_rate=0.2,\n",
    "    max_depth=7,\n",
    "    n_estimators=100,\n",
    "    subsample=1.0,\n",
    "    scale_pos_weight=3,\n",
    "    eval_metric='logloss',  # Optional, based on your metric of choice\n",
    "    #use_label_encoder=False\n",
    ")\n",
    "model_3 = Modeling(xgb, preprocessor, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 324 candidates, totalling 1620 fits\n",
      "Best parameters found:  {'colsample_bytree': 1.0, 'gamma': 0, 'learning_rate': 0.2, 'max_depth': 7, 'n_estimators': 100, 'subsample': 1.0}\n",
      "Best cross-validation score: 0.83\n"
     ]
    }
   ],
   "source": [
    "# Define parameter grid\n",
    "param_grid = {\n",
    "    'n_estimators': [100, 200, 300],\n",
    "    'learning_rate': [0.01, 0.1, 0.2],\n",
    "    'max_depth': [3, 5, 7],\n",
    "    'subsample': [0.8, 1.0],\n",
    "    'colsample_bytree': [0.8, 1.0],\n",
    "    'gamma': [0, 0.1, 0.2],\n",
    "}\n",
    "\n",
    "# Initialize GridSearchCV\n",
    "grid_search = GridSearchCV(xgb, param_grid=param_grid, \n",
    "                           scoring='accuracy', cv=5, verbose=1, n_jobs=-1)\n",
    "\n",
    "# Fit GridSearchCV to the data\n",
    "grid_search.fit(X_train_preprocessed, y_train)\n",
    "\n",
    "# Get the best parameters and score\n",
    "print(\"Best parameters found: \", grid_search.best_params_)\n",
    "print(\"Best cross-validation score: {:.2f}\".format(grid_search.best_score_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The model(with normal preprocessing) has an accuracy of 83.73%\n"
     ]
    }
   ],
   "source": [
    "fitted_model_3 = model_3.train_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "#fitted_model_3_smote = model_3.train_with_smote()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import AdaBoostClassifier\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "ada = AdaBoostClassifier()\n",
    "model_4 = Modeling(ada, preprocessor, X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n",
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "The model(with normal preprocessing) has an accuracy of 80.27%\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\user\\anaconda3\\Lib\\site-packages\\sklearn\\utils\\validation.py:1143: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples, ), for example using ravel().\n",
      "  y = column_or_1d(y, warn=True)\n"
     ]
    }
   ],
   "source": [
    "fitted_model_4 = model_4.train_base()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fitted_model_4_smote = model_4.train_with_smote()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The logistic regression model and the xgboost are the best performing with an accuracy of about 82%."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 0.3283582089552239\n",
      "Precision Score: 0.4583333333333333\n",
      "F1 Score: 0.3826086956521739\n"
     ]
    }
   ],
   "source": [
    "model_1.evaluate_on_test(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Recall Score: 0.5074626865671642\n",
      "Precision Score: 0.576271186440678\n",
      "F1 Score: 0.5396825396825398\n"
     ]
    }
   ],
   "source": [
    "model_3.evaluate_on_test(X_test, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
